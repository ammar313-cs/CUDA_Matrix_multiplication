{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moAo1Tnq1qM3",
        "outputId": "fa308181-a469-415a-9a63-4bfada38cb65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-llnn3p19\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-llnn3p19\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 0a71d56e5dce3ff1f0dd2c47c29367629262f527\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4293 sha256=7dc0b6a3a589156ea1993706ab21d59de9e54f6837359b61f41520b794f5da4b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-hn8ajl6_/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7H7OBNM1-yt",
        "outputId": "3b917dac-8730-4ac0-b2fe-c4f857788491"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "const int TILE_SIZE = 2;\n",
        "\n",
        "\n",
        "__global__ void matrixMul(const int *A, const int *B, int *C, int N) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    __shared__ int sA[TILE_SIZE][TILE_SIZE];\n",
        "    __shared__ int sB[TILE_SIZE][TILE_SIZE];\n",
        "\n",
        "    int result = 0;\n",
        "\n",
        "    for (int i = 0; i < (N + TILE_SIZE - 1) / TILE_SIZE; ++i) {\n",
        "        if ((row < N) && (i * TILE_SIZE + threadIdx.x < N)) {\n",
        "            sA[threadIdx.y][threadIdx.x] = A[row * N + i * TILE_SIZE + threadIdx.x];\n",
        "        } else {\n",
        "            sA[threadIdx.y][threadIdx.x] = 0;\n",
        "        }\n",
        "\n",
        "        if ((col < N) && (i * TILE_SIZE + threadIdx.y < N)) {\n",
        "            sB[threadIdx.y][threadIdx.x] = B[(i * TILE_SIZE + threadIdx.y) * N + col];\n",
        "        } else {\n",
        "            sB[threadIdx.y][threadIdx.x] = 0;\n",
        "        }\n",
        "\n",
        "        __syncthreads();\n",
        "\n",
        "        for (int j = 0; j < TILE_SIZE; ++j) {\n",
        "            result += sA[threadIdx.y][j] * sB[j][threadIdx.x];\n",
        "        }\n",
        "\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    if (row < N && col < N) {\n",
        "        C[row * N + col] = result;\n",
        "    }\n",
        "\n",
        "    // Debugging output\n",
        "    if (threadIdx.x == 0 && threadIdx.y == 0 && blockIdx.x == 0 && blockIdx.y == 0) {\n",
        "        printf(\"ThreadIdx: (%d, %d), BlockIdx: (%d, %d), Result: %d\\n\", threadIdx.x, threadIdx.y, blockIdx.x, blockIdx.y, result);\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "void printMatrix(const int *matrix, int rows, int cols) {\n",
        "    for (int i = 0; i < rows; ++i) {\n",
        "        for (int j = 0; j < cols; ++j) {\n",
        "            std::cout << matrix[i * cols + j] << \" \";  // Print without setw\n",
        "        }\n",
        "        std::cout << std::endl;\n",
        "    }\n",
        "    std::cout << std::endl;\n",
        "}\n",
        "\n",
        "\n",
        "int main() {\n",
        "    const int N = 3;\n",
        "\n",
        "    const int A[N][N] = {{1, 2, 3}, {4, 5, 6}, {7, 8, 9}};\n",
        "    const int B[N][N] = {{9, 8, 7}, {6, 5, 4}, {3, 2, 1}};\n",
        "\n",
        "\n",
        "    int C_cpu[N][N]; // Result matrix from CPU\n",
        "    int C_gpu[N][N]; // Result matrix from GPU\n",
        "\n",
        "\n",
        "    int *d_A, *d_B, *d_C;\n",
        "    cudaMalloc((void **)&d_A, N * N * sizeof(int));\n",
        "    cudaMalloc((void **)&d_B, N * N * sizeof(int));\n",
        "    cudaMalloc((void **)&d_C, N * N * sizeof(int));\n",
        "\n",
        "\n",
        "    cudaMemcpy(d_A, &A[0][0], N * N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, &B[0][0], N * N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "\n",
        "    dim3 blockDim(2, 2);\n",
        "    dim3 gridDim((N + blockDim.x - 1) / blockDim.x, (N + blockDim.y - 1) / blockDim.y);\n",
        "\n",
        "\n",
        "    matrixMul<<<gridDim, blockDim>>>(d_A, d_B, d_C, N);\n",
        "\n",
        "\n",
        "    cudaMemcpy(&C_gpu[0][0], d_C, N * N * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        for (int j = 0; j < N; ++j) {\n",
        "            C_cpu[i][j] = 0;\n",
        "            for (int k = 0; k < N; ++k) {\n",
        "                C_cpu[i][j] += A[i][k] * B[k][j];\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "\n",
        "    std::cout << \"Matrix A:\" << std::endl;\n",
        "    printMatrix(&A[0][0], N, N);\n",
        "    std::cout << \"Matrix B:\" << std::endl;\n",
        "    printMatrix(&B[0][0], N, N);\n",
        "    std::cout << \"Result from CPU (C_cpu):\" << std::endl;\n",
        "    printMatrix(&C_cpu[0][0], N, N);\n",
        "\n",
        "\n",
        "    std::cout << \"Result from GPU (C_gpu):\" << std::endl;\n",
        "    printMatrix(&C_gpu[0][0], N, N);\n",
        "\n",
        "\n",
        "    bool resultMatch = true;\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        for (int j = 0; j < N; ++j) {\n",
        "            if (C_cpu[i][j] != C_gpu[i][j]) {\n",
        "                resultMatch = false;\n",
        "                break;\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if (resultMatch) {\n",
        "        std::cout << \"Results match between CPU and GPU implementations.\" << std::endl;\n",
        "    } else {\n",
        "        std::cout << \"Results do not match between CPU and GPU implementations.\" << std::endl;\n",
        "    }\n",
        "\n",
        "\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10p8CmRf30Qs",
        "outputId": "08d35013-f292-43f6-a555-1bfb5d393842"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ThreadIdx: (0, 0), BlockIdx: (0, 0), Result: 30\n",
            "Matrix A:\n",
            "1 2 3 \n",
            "4 5 6 \n",
            "7 8 9 \n",
            "\n",
            "Matrix B:\n",
            "9 8 7 \n",
            "6 5 4 \n",
            "3 2 1 \n",
            "\n",
            "Result from CPU (C_cpu):\n",
            "30 24 18 \n",
            "84 69 54 \n",
            "138 114 90 \n",
            "\n",
            "Result from GPU (C_gpu):\n",
            "30 24 18 \n",
            "84 69 54 \n",
            "138 114 90 \n",
            "\n",
            "Results match between CPU and GPU implementations.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-rVrW-gn37r2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}